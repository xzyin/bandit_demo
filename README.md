Bandit Demo
# 1. 优化点击率
* eps-greedy
* UCB
* Thompson Sampling
# 2. 利用周边信息优化点击率
* LinUCB
* Thompson Sampling
* Contextual Bandit工业实践:微软Azure Decision Service
# 3. 利用长期行为优化点击率
* MDP基础概念
* 价值迭代(Value Iteration)
* 策略迭代(Policy Iteration)
